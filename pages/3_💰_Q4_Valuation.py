"""
Q4: Trang Ph√¢n T√≠ch ƒê·ªãnh Gi√°
"""
import streamlit as st
import pandas as pd
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from data.loader import merge_all_data
from analysis.valuation import (
    calculate_valuation_percentiles, analyze_percentile_returns,
    valuation_summary, compare_valuation_metrics, predict_forward_return,
    identify_valuation_zones
)
from visualization.charts_q4 import (
    create_percentile_timeseries, create_decile_returns_chart,
    create_valuation_gauge, create_zone_comparison_chart
)
from config import config_banking
from config.config import CACHE_TTL
from utils.constants import *
from utils.logo_helper import display_sidebar_logo

# All 17 banking tickers (Valuation analysis doesn't require foreign trading data)
BANKING_TICKERS = [
    'VCB', 'TCB', 'MBB', 'ACB', 'VPB', 'BID', 'CTG',
    'STB', 'HDB', 'TPB', 'VIB', 'SSB', 'SHB', 'MSB',
    'LPB', 'OCB', 'EIB'
]

st.set_page_config(page_title="Q4: ƒê·ªãnh Gi√°", page_icon="üí∞", layout="wide")

# Display logo in sidebar
display_sidebar_logo()

st.title("üí∞ Q4: Ph√¢n T√≠ch Ph√¢n V·ªã ƒê·ªãnh Gi√°")

st.markdown("""
**C√¢u H·ªèi Nghi√™n C·ª©u**: ƒê·ªãnh gi√° r·∫ª (ph√¢n v·ªã PE/PB th·∫•p) c√≥ d·ª± ƒëo√°n l·ª£i nhu·∫≠n cao h∆°n kh√¥ng?

Ph√¢n t√≠ch n√†y xem x√©t li·ªáu mua c·ªï phi·∫øu khi ch√∫ng r·∫ª v·ªÅ m·∫∑t l·ªãch s·ª≠ c√≥ d·∫´n ƒë·∫øn l·ª£i nhu·∫≠n t·ªët h∆°n hay kh√¥ng.
""")

# Load data
@st.cache_data(ttl=CACHE_TTL)
def load_all_data():
    return merge_all_data(config_banking)

@st.cache_data(ttl=CACHE_TTL)
def prepare_valuation_data(ticker):
    data = load_all_data()
    df = data[ticker].copy()
    df = calculate_valuation_percentiles(df)
    df = identify_valuation_zones(df)
    return df

# Sidebar
st.sidebar.header("B·ªô L·ªçc")
selected_ticker = st.sidebar.selectbox("Ch·ªçn M√£ C·ªï Phi·∫øu", BANKING_TICKERS)
selected_metric = st.sidebar.selectbox("Ch·ªâ S·ªë ƒê·ªãnh Gi√°", [PE, PB, PCFS])
forward_horizon = st.sidebar.slider("K·ª≥ H·∫°n L·ª£i Nhu·∫≠n (ng√†y)", 1, 60, 30)

# Load data
with st.spinner(f"ƒêang t·∫£i d·ªØ li·ªáu {selected_ticker}..."):
    df = prepare_valuation_data(selected_ticker)

# Current valuation summary
st.header(f"ƒê·ªãnh Gi√° Hi·ªán T·∫°i - {selected_ticker}")

summary = valuation_summary(df, metrics=[PE, PB, PCFS])

if 'date' in summary:
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Ng√†y", str(summary['date'])[:10] if summary['date'] else "N/A")

    metrics_display = [PE, PB, PCFS]
    cols = [col2, col3, col4]

    for metric, col in zip(metrics_display, cols):
        with col:
            val = summary['valuations'].get(metric)
            pct = summary['percentiles'].get(metric)
            zone = summary['zones'].get(metric, 'N/A')

            if val and pct:
                st.metric(
                    f"{metric.upper()}",
                    f"{val:.2f}",
                    delta=f"{pct:.0f}% ile | {zone}"
                )

# Gauge chart
st.header(f"V·ªã Tr√≠ Ph√¢n V·ªã {selected_metric.upper()}")

percentile_col = f'{selected_metric}_percentile'
if percentile_col in df.columns:
    current_pct = df[percentile_col].iloc[-1]

    if not pd.isna(current_pct):
        fig_gauge = create_valuation_gauge(current_pct, selected_metric)
        st.plotly_chart(fig_gauge, use_container_width=True)
    else:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ph√¢n v·ªã hi·ªán t·∫°i")

# Historical percentile
st.header(f"Ph√¢n V·ªã L·ªãch S·ª≠ {selected_metric.upper()}")

fig_timeseries = create_percentile_timeseries(df, selected_metric, selected_ticker)
st.plotly_chart(fig_timeseries, use_container_width=True)

# Decile analysis
st.header(f"L·ª£i Nhu·∫≠n Theo Ph√¢n V·ªã {selected_metric.upper()}")

with st.spinner("ƒêang ph√¢n t√≠ch l·ª£i nhu·∫≠n theo nh√≥m m∆∞·ªùi..."):
    analysis = analyze_percentile_returns(df, percentile_col, forward_horizon)

if 'error' not in analysis:
    # Summary metrics
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "LN V√πng R·∫ª (0-20%)",
            f"{analysis['cheap_zone_return']:.2%}",
            delta=None
        )

    with col2:
        st.metric(
            "LN V√πng ƒê·∫Øt (80-100%)",
            f"{analysis['expensive_zone_return']:.2%}",
            delta=None
        )

    with col3:
        spread = analysis['cheap_expensive_spread']
        st.metric(
            "Ch√™nh L·ªách R·∫ª - ƒê·∫Øt",
            f"{spread:.2%}",
            delta="D∆∞∆°ng l√† t·ªët" if spread > 0 else "√Çm l√† x·∫•u"
        )

    # Decile bar chart
    fig_decile = create_decile_returns_chart(
        analysis['decile_stats'],
        selected_metric,
        selected_ticker
    )
    st.plotly_chart(fig_decile, use_container_width=True)

    # Zone comparison
    col1, col2 = st.columns(2)

    with col1:
        fig_zones = create_zone_comparison_chart(
            analysis['cheap_zone_return'],
            analysis['expensive_zone_return'],
            selected_metric
        )
        st.plotly_chart(fig_zones, use_container_width=True)

    with col2:
        st.subheader("Ki·ªÉm ƒê·ªãnh Th·ªëng K√™")

        st.write("**Ki·ªÉm ƒê·ªãnh ƒê∆°n ƒêi·ªáu** (K·ª≥ v·ªçng xu h∆∞·ªõng gi·∫£m)")
        mono = analysis['monotonicity']
        st.write(f"- T∆∞∆°ng quan Spearman: {mono['correlation']:.4f}")
        st.write(f"- P-value: {mono[P_VALUE]:.4f}")
        st.write(f"- ƒê∆°n ƒëi·ªáu: {'‚úÖ' if mono['is_monotonic'] else '‚ùå'}")

        st.write("\n**Ki·ªÉm ƒê·ªãnh ANOVA** (LN kh√°c nhau gi·ªØa c√°c nh√≥m?)")
        anova = analysis['anova']
        st.write(f"- F-statistic: {anova.get('f_stat', 'N/A'):.2f}")
        st.write(f"- P-value: {anova.get(P_VALUE, 'N/A'):.4f}")
        st.write(f"- C√≥ √Ω nghƒ©a: {'‚úÖ' if anova.get('significant') else '‚ùå'}")

    # Detailed decile table
    st.subheader("Th·ªëng K√™ Nh√≥m M∆∞·ªùi Chi Ti·∫øt")
    st.dataframe(
        analysis['decile_stats'].style.format({
            'mean': '{:.4f}',
            'std': '{:.4f}',
            'median': '{:.4f}',
            'count': '{:.0f}'
        }),
        use_container_width=True
    )

else:
    st.error(analysis['error'])

# Prediction tool
st.header("C√¥ng C·ª• D·ª± ƒêo√°n L·ª£i Nhu·∫≠n")

st.markdown("""
Nh·∫≠p gi√° tr·ªã ph√¢n v·ªã ƒë·ªÉ xem l·ª£i nhu·∫≠n k·ª≥ v·ªçng d·ª±a tr√™n c√°c m√¥ h√¨nh l·ªãch s·ª≠.
""")

input_percentile = st.slider(
    f"Ph√¢n V·ªã {selected_metric.upper()} Hi·ªán T·∫°i",
    0.0, 100.0,
    summary['percentiles'].get(selected_metric, 50.0) if summary['percentiles'].get(selected_metric) else 50.0
)

if st.button("D·ª± ƒêo√°n L·ª£i Nhu·∫≠n"):
    prediction = predict_forward_return(df, input_percentile, percentile_col, forward_horizon)

    if 'error' not in prediction:
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("L·ª£i Nhu·∫≠n K·ª≥ V·ªçng", f"{prediction['expected_return']:.2%}")

        with col2:
            st.metric("Kho·∫£ng Tin C·∫≠y (95%)",
                     f"{prediction['confidence_low']:.2%} ƒë·∫øn {prediction['confidence_high']:.2%}")

        with col3:
            st.metric("K√≠ch Th∆∞·ªõc M·∫´u", f"{int(prediction['sample_size'])}")

        st.info(f"D·ª±a tr√™n ph√¢n v·ªã: {prediction['current_percentile']:.1f}% ‚Üí Nh√≥m m∆∞·ªùi {prediction['decile']}")
    else:
        st.error(prediction['error'])

# Metric comparison
st.header("So S√°nh C√°c Ch·ªâ S·ªë ƒê·ªãnh Gi√°")

comparison = compare_valuation_metrics(df, forward_horizon)

if comparison:
    comp_data = []
    for metric, results in comparison.items():
        comp_data.append({
            'Ch·ªâ S·ªë': metric.upper(),
            'T∆∞∆°ng Quan ƒê∆°n ƒêi·ªáu': results['monotonicity_correlation'],
            'P-val ƒê∆°n ƒêi·ªáu': results['monotonicity_pvalue'],
            'Ch√™nh L·ªách R·∫ª-ƒê·∫Øt': results['cheap_expensive_spread'],
            'P-val ANOVA': results['anova_pvalue']
        })

    comp_df = pd.DataFrame(comp_data)

    st.dataframe(
        comp_df.style.format({
            'T∆∞∆°ng Quan ƒê∆°n ƒêi·ªáu': '{:.4f}',
            'P-val ƒê∆°n ƒêi·ªáu': '{:.4f}',
            'Ch√™nh L·ªách R·∫ª-ƒê·∫Øt': '{:.2%}',
            'P-val ANOVA': '{:.4f}'
        }),
        use_container_width=True
    )

    st.caption("""
    **Gi·∫£i Th√≠ch**:
    - **T∆∞∆°ng Quan ƒê∆°n ƒêi·ªáu √Çm**: Ph√¢n v·ªã th·∫•p ‚Üí LN cao h∆°n (t·ªët)
    - **Ch√™nh L·ªách R·∫ª-ƒê·∫Øt D∆∞∆°ng**: R·∫ª v∆∞·ª£t tr·ªôi h∆°n ƒë·∫Øt (t·ªët)
    - **P-value Th·∫•p**: M√¥ h√¨nh c√≥ √Ω nghƒ©a th·ªëng k√™
    """)

# Current PE/PB comparison across all banks
st.header("So S√°nh PE/PB Hi·ªán T·∫°i - T·∫•t C·∫£ 17 Ng√¢n H√†ng")

st.markdown("""
Bi·ªÉu ƒë·ªì d∆∞·ªõi ƒë√¢y hi·ªÉn th·ªã PE v√† PB hi·ªán t·∫°i c·ªßa t·∫•t c·∫£ 17 ng√¢n h√†ng, s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn.
""")

@st.cache_data(ttl=CACHE_TTL)
def get_all_banks_current_valuation():
    """Get current PE and PB for all banks"""
    data = load_all_data()

    results = []
    for ticker in BANKING_TICKERS:
        if ticker in data:
            df = data[ticker]
            if not df.empty:
                # Get most recent data
                latest = df.iloc[-1]

                pe_val = latest.get(PE, None)
                pb_val = latest.get(PB, None)
                date_val = latest.get(DATE, None)

                results.append({
                    'Ticker': ticker,
                    'PE': pe_val if not pd.isna(pe_val) else None,
                    'PB': pb_val if not pd.isna(pb_val) else None,
                    'Date': date_val
                })

    return pd.DataFrame(results)

with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu ƒë·ªãnh gi√° t·∫•t c·∫£ ng√¢n h√†ng..."):
    all_banks_df = get_all_banks_current_valuation()

# Filter out None values and sort
pe_data = all_banks_df[all_banks_df['PE'].notna()].sort_values('PE', ascending=False)
pb_data = all_banks_df[all_banks_df['PB'].notna()].sort_values('PB', ascending=False)

col1, col2 = st.columns(2)

with col1:
    st.subheader("PE Theo Th·ª© T·ª± Gi·∫£m D·∫ßn")

    if not pe_data.empty:
        import plotly.graph_objects as go

        fig_pe = go.Figure()

        fig_pe.add_trace(go.Bar(
            x=pe_data['Ticker'],
            y=pe_data['PE'],
            marker_color='steelblue',
            text=pe_data['PE'].apply(lambda x: f'{x:.2f}'),
            textposition='outside'
        ))

        fig_pe.update_layout(
            title='PE Hi·ªán T·∫°i - 17 Ng√¢n H√†ng',
            xaxis_title='M√£ C·ªï Phi·∫øu',
            yaxis_title='PE',
            height=500,
            template='plotly_white',
            showlegend=False
        )

        st.plotly_chart(fig_pe, use_container_width=True)

        # Show latest date
        latest_date = pe_data['Date'].iloc[0]
        st.caption(f"D·ªØ li·ªáu m·ªõi nh·∫•t: {str(latest_date)[:10] if latest_date else 'N/A'}")
    else:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu PE")

with col2:
    st.subheader("PB Theo Th·ª© T·ª± Gi·∫£m D·∫ßn")

    if not pb_data.empty:
        fig_pb = go.Figure()

        fig_pb.add_trace(go.Bar(
            x=pb_data['Ticker'],
            y=pb_data['PB'],
            marker_color='coral',
            text=pb_data['PB'].apply(lambda x: f'{x:.2f}'),
            textposition='outside'
        ))

        fig_pb.update_layout(
            title='PB Hi·ªán T·∫°i - 17 Ng√¢n H√†ng',
            xaxis_title='M√£ C·ªï Phi·∫øu',
            yaxis_title='PB',
            height=500,
            template='plotly_white',
            showlegend=False
        )

        st.plotly_chart(fig_pb, use_container_width=True)

        # Show latest date
        latest_date = pb_data['Date'].iloc[0]
        st.caption(f"D·ªØ li·ªáu m·ªõi nh·∫•t: {str(latest_date)[:10] if latest_date else 'N/A'}")
    else:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu PB")

# Summary statistics
st.subheader("Th·ªëng K√™ T·ªïng H·ª£p")

col1, col2, col3 = st.columns(3)

with col1:
    if not pe_data.empty:
        st.metric("PE Trung B√¨nh", f"{pe_data['PE'].mean():.2f}")
        st.metric("PE Trung V·ªã", f"{pe_data['PE'].median():.2f}")

with col2:
    if not pb_data.empty:
        st.metric("PB Trung B√¨nh", f"{pb_data['PB'].mean():.2f}")
        st.metric("PB Trung V·ªã", f"{pb_data['PB'].median():.2f}")

with col3:
    if not pe_data.empty and not pb_data.empty:
        st.metric("S·ªë Ng√¢n H√†ng C√≥ PE", f"{len(pe_data)}/17")
        st.metric("S·ªë Ng√¢n H√†ng C√≥ PB", f"{len(pb_data)}/17")

# Interpretation
st.header("Gi·∫£i Th√≠ch")

st.info("""
**C√°ch s·ª≠ d·ª•ng ph√¢n t√≠ch n√†y:**

- **V√πng R·∫ª (ph√¢n v·ªã 0-20%)**: ƒê·ªãnh gi√° th·∫•p v·ªÅ m·∫∑t l·ªãch s·ª≠, c√≥ th·ªÉ l√† ƒëi·ªÉm v√†o t·ªët
- **V√πng H·ª£p L√Ω (ph√¢n v·ªã 40-60%)**: ƒê·ªãnh gi√° trung b√¨nh
- **V√πng ƒê·∫Øt (ph√¢n v·ªã 80-100%)**: ƒê·ªãnh gi√° cao v·ªÅ m·∫∑t l·ªãch s·ª≠, c·∫ßn th·∫≠n tr·ªçng

**Ch√™nh L·ªách R·∫ª-ƒê·∫Øt D∆∞∆°ng** g·ª£i √Ω hi·ªáu ·ª©ng gi√° tr·ªã: mua r·∫ª hi·ªáu qu·∫£!

**Xu h∆∞·ªõng gi·∫£m ƒë∆°n ƒëi·ªáu** trong l·ª£i nhu·∫≠n nh√≥m m∆∞·ªùi x√°c nh·∫≠n m√¥ h√¨nh.
""")

st.warning("""
‚ö†Ô∏è **L∆∞u √ù Quan Tr·ªçng**:
- Ph√¢n v·ªã ƒë·ªãnh gi√° s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t 3 nƒÉm (756 ng√†y giao d·ªãch)
- M·ªëi quan h·ªá trong qu√° kh·ª© c√≥ th·ªÉ kh√¥ng duy tr√¨ trong t∆∞∆°ng lai
- Xem x√©t c√°c y·∫øu t·ªë kh√°c ngo√†i ƒë·ªãnh gi√°
- ƒê√¢y l√† nghi√™n c·ª©u, kh√¥ng ph·∫£i l·ªùi khuy√™n ƒë·∫ßu t∆∞
""")
